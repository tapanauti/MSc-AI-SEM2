{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSAxIRPv-9vY"
      },
      "source": [
        "Part 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEQBY4BXoK3-"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "sns.set()"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-g636ngpZ50"
      },
      "source": [
        "def initialize_parameters(n_x, n_h, n_y):\n",
        "    \n",
        "    np.random.seed(2) \n",
        "    \n",
        "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
        "    b1 = np.zeros(shape=(n_h, 1))\n",
        "    W2 = np.random.randn(n_y, n_h) * 0.01\n",
        "    b2 = np.zeros(shape=(n_y, 1))\n",
        "    \n",
        "    assert (W1.shape == (n_h, n_x))\n",
        "    assert (b1.shape == (n_h, 1))\n",
        "    assert (W2.shape == (n_y, n_h))\n",
        "    assert (b2.shape == (n_y, 1))\n",
        "    \n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2}\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0wERTGlpcvf"
      },
      "source": [
        "def relu(x):\n",
        "    return x*(x>0)\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "def tanh(x):\n",
        "    return (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvBx_Z-lpcyh"
      },
      "source": [
        "def forward_pass(X, parameters):\n",
        "    \n",
        "    # to make forward pass calculations we need W1 and W2 so we will extract them from dictionary parameters\n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "    b1 = parameters['b1']\n",
        "    b2 = parameters['b2']\n",
        "\n",
        "    #print(W1)\n",
        "    # first layer calculations - hidden layer calculations\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tanh(Z1)  # activation in the first layer is tanh\n",
        "    \n",
        "    # output layer calculations\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = sigmoid(Z2)# A2 are predictions, y_hat\n",
        "    \n",
        "    # cache values for backpropagation calculations\n",
        "    cache = {'Z1':Z1,\n",
        "             'A1':A1,\n",
        "             'Z2':Z2,\n",
        "             'A2':A2\n",
        "            }\n",
        "    # print(A2.shape)\n",
        "    return A2, cache"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWInDi_5pc0-"
      },
      "source": [
        "def backward_pass(parameters, cache, X, Y):\n",
        "    \n",
        "    # unpack paramaeters and cache to get values for backpropagation calculations\n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "    \n",
        "    Z1 = cache['Z1']\n",
        "    A1 = cache['A1']\n",
        "    Z2 = cache['Z2']\n",
        "    A2 = cache['A2']\n",
        "    \n",
        "    m = X.shape[1] # number of examples in a training set\n",
        "    #print(A2)\n",
        "    #print(A2.shape)\n",
        "    dZ2= A2 - Y\n",
        "    \n",
        "    \n",
        "    dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
        "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)   # keepdims - prevents python to output rank 1 array (n,)\n",
        "    \n",
        "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2)) # we use tanh activation function\n",
        "    dW1 = (1 / m) * np.dot(dZ1, X.T)  \n",
        "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "    \n",
        "    grads = {\"dW1\": dW1,\n",
        "             \"db1\": db1,\n",
        "             \"dW2\": dW2,\n",
        "             \"db2\": db2}\n",
        "    \n",
        "    return grads"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVlCAscKpc30"
      },
      "source": [
        "def update_parameters(parameters, learning_rate, grads):\n",
        "    \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    \n",
        "    dW1 = grads['dW1']\n",
        "    db1 = grads['db1']\n",
        "    dW2 = grads['dW2']\n",
        "    db2 = grads['db2']\n",
        "    \n",
        "    W1 = W1 - learning_rate * dW1\n",
        "    b1 = b1 - learning_rate * db1\n",
        "    W2 = W2 - learning_rate * dW2\n",
        "    b2 = b2 - learning_rate * db2\n",
        "    \n",
        "    # updated parameters\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2}\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaMIqgVqpc6k"
      },
      "source": [
        "def NN_model(X,Y,n_h, num_iterations, learning_rate):\n",
        "    \n",
        "    n_x = X.shape[0] # size of an input layer = number of features \n",
        "    n_y = Y.shape[0] # size of an output layer\n",
        "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
        "    \n",
        "    #unpack parameters\n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "        A2, cache = forward_pass(X, parameters)\n",
        "        grads = backward_pass(parameters, cache, X, Y)\n",
        "        parameters = update_parameters(parameters, learning_rate, grads)\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JPuZwKqpc9S"
      },
      "source": [
        "def predict(parameters, X):\n",
        "    \n",
        "    A2, cache = forward_pass(X, parameters)\n",
        "    predictions = np.round(A2)\n",
        "    \n",
        "    return predictions"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggf5LiUQqqfi"
      },
      "source": [
        " (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzkfBbAJvRdJ"
      },
      "source": [
        "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miDM8FzoptXO"
      },
      "source": [
        "arr = [y_train.tolist()]\n",
        "y_train = np.array(arr)\n",
        "\n",
        "arr1 = [y_test.tolist()]\n",
        "y_test = np.array(arr1)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRoZRfhiwMdN"
      },
      "source": [
        "x_train = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in x_train])\n",
        "x_test = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in x_test])\n",
        "#x_train.shape"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmw7iuawsHPY",
        "outputId": "5635ccf6-6ee6-4ce3-9fd7-1388070ea9bb"
      },
      "source": [
        "x_train.size"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51200000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgjrhIiVuoTO"
      },
      "source": [
        "# x_train  = x_train/255\n",
        "# x_test  = x_test/255"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5wwkWp7zCui"
      },
      "source": [
        "# one_hot_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
        "# one_hot_encoder.fit(y_train)\n",
        "# y_train = one_hot_encoder.transform(y_train)\n",
        "# y_test = one_hot_encoder.transform(y_test)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOtHT5lizC0m"
      },
      "source": [
        "# x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "# x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "NS7Y25izzC3L",
        "outputId": "633f31fe-9eb5-436f-ada8-59ca91da056a"
      },
      "source": [
        "num_iterations = 20000\n",
        "learning_rate = 0.1\n",
        "n_h = 4\n",
        "parameters_final = NN_model(x_train.T,y_train.T,n_h, num_iterations, learning_rate)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-4.16757847e-03 -5.62668272e-04 -2.13619610e-02  1.64027081e-02\n",
            "  -1.79343559e-02 -8.41747366e-03  5.02881417e-03 -1.24528809e-02\n",
            "  -1.05795222e-02 -9.09007615e-03  5.51454045e-03  2.29220801e-02\n",
            "   4.15393930e-04 -1.11792545e-02  5.39058321e-03 -5.96159700e-03\n",
            "  -1.91304965e-04  1.17500122e-02 -7.47870949e-03  9.02525097e-05\n",
            "  -8.78107893e-03 -1.56434170e-03  2.56570452e-03 -9.88779049e-03\n",
            "  -3.38821966e-03 -2.36184031e-03 -6.37655012e-03 -1.18761229e-02\n",
            "  -1.42121723e-02 -1.53495196e-03 -2.69056960e-03  2.23136679e-02]\n",
            " [-2.43476758e-02  1.12726505e-03  3.70444537e-03  1.35963386e-02\n",
            "   5.01857207e-03 -8.44213704e-03  9.76147160e-08  5.42352572e-03\n",
            "  -3.13508197e-03  7.71011738e-03 -1.86809065e-02  1.73118467e-02\n",
            "   1.46767801e-02 -3.35677339e-03  6.11340780e-03  4.79705919e-04\n",
            "  -8.29135289e-03  8.77102184e-04  1.00036589e-02 -3.81092518e-03\n",
            "  -3.75669423e-03 -7.44707629e-04  4.33496330e-03  1.27837923e-02\n",
            "  -6.34679305e-03  5.08396243e-03  2.16116006e-03 -1.85861239e-02\n",
            "  -4.19316482e-03 -1.32328898e-03 -3.95702397e-04  3.26003433e-03]\n",
            " [-2.04032305e-02  4.62555231e-04 -6.77675577e-03 -1.43943903e-02\n",
            "   5.24296430e-03  7.35279576e-03 -6.53250268e-03  8.42456282e-03\n",
            "  -3.81516482e-03  6.64890091e-04 -1.09873895e-02  1.58448706e-02\n",
            "  -2.65944946e-02 -9.14526229e-04  6.95119605e-03 -2.03346655e-02\n",
            "  -1.89469265e-03 -7.72186654e-04  8.24703005e-03  1.24821292e-02\n",
            "  -4.03892269e-03 -1.38451867e-02  1.36723542e-02  1.21788563e-02\n",
            "  -4.62005348e-03  3.50888494e-03  3.81866234e-03  5.66275441e-03\n",
            "   2.04207979e-03  1.40669624e-02 -1.73795950e-02  1.04082395e-02]\n",
            " [ 3.80471970e-03 -2.17135269e-03  1.17353150e-02 -2.34360319e-02\n",
            "   1.16152149e-02  3.86078048e-03 -1.13313327e-02  4.33092555e-03\n",
            "  -3.04086439e-03  2.58529487e-02  1.83533272e-02  4.40689872e-03\n",
            "  -7.19253841e-03 -5.83414595e-03 -3.25049628e-03 -5.60234506e-03\n",
            "  -9.02246068e-03 -5.90972275e-03 -2.76179492e-03 -5.16883894e-03\n",
            "  -6.98589950e-03 -9.28891925e-03  2.55043824e-02 -1.47317325e-02\n",
            "  -1.02141473e-02  4.32395701e-03 -3.23580070e-03  4.23824708e-03\n",
            "   7.99179995e-03  1.26261366e-02  7.51964849e-03 -9.93760983e-03]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-169-d2e2c01877f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mparameters_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-162-1dfb8b09697b>\u001b[0m in \u001b[0;36mNN_model\u001b[0;34m(X, Y, n_h, num_iterations, learning_rate)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mA2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-159-ce49199aef68>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(X, parameters)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# first layer calculations - hidden layer calculations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# activation in the first layer is tanh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,32,50000) (4,1) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggMIlQaf6PUf",
        "outputId": "9a0f1e79-ce5b-4270-9b65-b18ef802f1f7"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLuXVU8KzC6R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}